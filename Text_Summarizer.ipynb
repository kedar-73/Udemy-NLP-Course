{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVigIIwzSIb+0v+MWzQ26Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kedar-73/Udemy-NLP-Course/blob/main/Text_Summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oLvKERvFZF6",
        "outputId": "7b2de172-108a-4660-885f-e3ad014f903c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk scikit-learn networkx\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import networkx as nx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. It involves analyzing, understanding, and generating human language. NLP is used in applications like chatbots, translation services, and sentiment analysis. With the rise of machine learning, NLP has become more powerful and accurate. Techniques like tokenization, stemming, and lemmatization help in preprocessing text. Advanced models like transformers have revolutionized NLP tasks.\n",
        "\"\"\"\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkWCs_hOJhxg",
        "outputId": "a8f09dd0-8e33-441a-f951-70b3a1a6531d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. It involves analyzing, understanding, and generating human language. NLP is used in applications like chatbots, translation services, and sentiment analysis. With the rise of machine learning, NLP has become more powerful and accurate. Techniques like tokenization, stemming, and lemmatization help in preprocessing text. Advanced models like transformers have revolutionized NLP tasks.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
        "\n",
        "punkt_param = PunktParameters()\n",
        "punkt_param.abbrev_types = set(['nlp', 'ai'])\n",
        "tokenizer = PunktSentenceTokenizer(punkt_param)\n",
        "\n",
        "sentences = tokenizer.tokenize(text)\n"
      ],
      "metadata": {
        "id": "dRHNICYZKiSF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(sentences)\n"
      ],
      "metadata": {
        "id": "dATYLc4HKnK4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix = cosine_similarity(tfidf_matrix)\n"
      ],
      "metadata": {
        "id": "Wouax97zM9qS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx_graph = nx.from_numpy_array(similarity_matrix)\n",
        "scores = nx.pagerank(nx_graph)\n",
        "print(scores)\n",
        "display(nx_graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "286ICqsMNBuW",
        "outputId": "545e2acd-ea45-4f1d-c2cf-6801204d1ce3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0.17378972772202902, 1: 0.15980456406323099, 2: 0.17754060176293843, 3: 0.16375544235528344, 4: 0.16490522208496464, 5: 0.16020444201155287}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x7a520b1bb650>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
        "summary = \" \".join([s for _, s in ranked_sentences[:3]])\n",
        "\n",
        "print(\"üìù Summary:\\n\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz-Dpro3NGKM",
        "outputId": "11ba027a-2d81-40fa-8360-f81d1bfc36d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Summary:\n",
            "\n",
            "NLP is used in applications like chatbots, translation services, and sentiment analysis. \n",
            "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. Techniques like tokenization, stemming, and lemmatization help in preprocessing text.\n"
          ]
        }
      ]
    }
  ]
}